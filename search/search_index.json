{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Intermediate Developer Course: Cloud &amp; DevOps Focus","text":"<p>This course is designed for developers with some prior programming experience (Python or Go recommended) who want to deepen their skills in programming best practices, cloud computing (specifically AWS), system design, and container orchestration with Kubernetes (focusing on AWS EKS).</p> <p>Target Audience: Intermediate Developers</p> <p>Prerequisites: Basic understanding of programming (Python or Go), familiarity with Linux/Unix command line, basic Git knowledge.</p> <p>Course Index &amp; Estimated Time Commitment:</p>"},{"location":"#module-1-advanced-programming-best-practices","title":"Module 1: Advanced Programming &amp; Best Practices","text":""},{"location":"#chapter-1-language-deep-dive-idiomatic-code","title":"Chapter 1: Language Deep Dive &amp; Idiomatic Code","text":"<ul> <li> <p>Content: Review of intermediate concepts, advanced language features (e.g., decorators/interfaces, concurrency models), error handling, code style, naming conventions.</p> </li> <li> <p>Estimated Time: 10 hours</p> </li> </ul>"},{"location":"#chapter-2-environment-dependencies-build-tools","title":"Chapter 2: Environment, Dependencies &amp; Build Tools","text":"<ul> <li> <p>Content: Virtual environments (venv/go modules), dependency management (pip/go mod), package structure, build processes.</p> </li> <li> <p>Estimated Time: 5 hours</p> </li> </ul>"},{"location":"#chapter-3-testing-strategies-70","title":"Chapter 3: Testing Strategies (70%)","text":"<ul> <li> <p>Content: Unit testing frameworks (e.g., <code>unittest</code>/<code>pytest</code> or Go's <code>testing</code>), mocking, test-driven development (TDD) principles, basic integration testing concepts.</p> </li> <li> <p>Estimated Time: 8 hours</p> </li> </ul>"},{"location":"#chapter-4-project-refactoring-enhancing-an-existing-application","title":"Chapter 4: Project - Refactoring &amp; Enhancing an Existing Application","text":"<ul> <li> <p>Content: Apply learned concepts to refactor a moderately complex application, improve test coverage, and implement new features following best practices.</p> </li> <li> <p>Estimated Time: 20 hours</p> </li> </ul>"},{"location":"#module-2-essential-algorithms","title":"Module 2: Essential Algorithms","text":""},{"location":"#chapter-5-sorting-algorithms","title":"Chapter 5: Sorting Algorithms","text":"<ul> <li> <p>Content: Implementation, time/space complexity analysis of Bubble Sort, Insertion Sort, Selection Sort, Merge Sort, Quick Sort, Heap Sort. Understanding trade-offs.</p> </li> <li> <p>Estimated Time: 12 hours</p> </li> </ul>"},{"location":"#chapter-6-searching-algorithms-hashing","title":"Chapter 6: Searching Algorithms &amp; Hashing","text":"<ul> <li> <p>Content: Implementation, time/space complexity analysis of Linear Search, Binary Search. Introduction to hash tables, collision resolution strategies.</p> </li> <li> <p>Estimated Time: 8 hours</p> </li> </ul>"},{"location":"#module-3-system-design-fundamentals","title":"Module 3: System Design Fundamentals","text":""},{"location":"#chapter-7-core-concepts-trade-offs","title":"Chapter 7: Core Concepts &amp; Trade-offs","text":"<ul> <li> <p>Content: Scalability (vertical vs. horizontal), Availability, Reliability, Consistency (CAP Theorem), Latency, Performance, Monitoring.</p> </li> <li> <p>Estimated Time: 10 hours</p> </li> </ul>"},{"location":"#chapter-8-system-building-blocks","title":"Chapter 8: System Building Blocks","text":"<ul> <li> <p>Content: Load Balancers, Databases (SQL vs. NoSQL, replication, sharding), Caching (strategies, Redis/Memcached), Message Queues (RabbitMQ/Kafka basics), Content Delivery Networks (CDNs).</p> </li> <li> <p>Estimated Time: 15 hours</p> </li> </ul>"},{"location":"#chapter-9-architectural-patterns","title":"Chapter 9: Architectural Patterns","text":"<ul> <li> <p>Content: Monoliths vs. Microservices, API Gateways, Service Discovery, Stateless vs. Stateful services, Asynchronous processing.</p> </li> <li> <p>Estimated Time: 12 hours</p> </li> </ul>"},{"location":"#chapter-10-system-design-case-studies","title":"Chapter 10: System Design Case Studies","text":"<ul> <li> <p>Content: Walkthroughs of designing common systems (e.g., URL shortener, social media feed, e-commerce backend). Applying concepts and making design choices.</p> </li> <li> <p>Estimated Time: 15 hours</p> </li> </ul>"},{"location":"#module-4-cloud-computing-with-aws-boto3","title":"Module 4: Cloud Computing with AWS &amp; Boto3","text":""},{"location":"#chapter-11-aws-core-services-overview","title":"Chapter 11: AWS Core Services Overview","text":"<ul> <li> <p>Content: Introduction to key services: EC2 (Instances), S3 (Storage), VPC (Networking), IAM (Security), RDS (Databases), CloudWatch (Monitoring).</p> </li> <li> <p>Estimated Time: 10 hours</p> </li> </ul>"},{"location":"#chapter-12-programmatic-aws-interaction-with-boto3-python","title":"Chapter 12: Programmatic AWS Interaction with Boto3 (Python)","text":"<ul> <li> <p>Content: Setting up Boto3, authentication (credentials, IAM roles), interacting with core services (EC2, S3, IAM) via the SDK.</p> </li> <li> <p>Estimated Time: 15 hours</p> </li> </ul>"},{"location":"#chapter-13-project-cloud-automation-scripts","title":"Chapter 13: Project - Cloud Automation Scripts","text":"<ul> <li> <p>Content: Develop Python scripts using Boto3 to automate common AWS tasks (e.g., launching/terminating EC2 instances based on tags, managing S3 bucket policies, creating IAM users/roles).</p> </li> <li> <p>Estimated Time: 20 hours</p> </li> </ul>"},{"location":"#module-5-kubernetes-aws-eks","title":"Module 5: Kubernetes &amp; AWS EKS","text":""},{"location":"#chapter-14-kubernetes-fundamentals","title":"Chapter 14: Kubernetes Fundamentals","text":"<ul> <li> <p>Content: Core concepts: Pods, Services, Deployments, ReplicaSets, Namespaces, ConfigMaps, Secrets, Persistent Volumes, Helm basics.</p> </li> <li> <p>Estimated Time: 15 hours</p> </li> </ul>"},{"location":"#chapter-15-introduction-to-amazon-eks","title":"Chapter 15: Introduction to Amazon EKS","text":"<ul> <li> <p>Content: EKS architecture (managed control plane, data plane options), creating an EKS cluster, <code>eksctl</code> basics.</p> </li> <li> <p>Estimated Time: 10 hours</p> </li> </ul>"},{"location":"#chapter-16-eks-vs-vanilla-kubernetes-key-differences","title":"Chapter 16: EKS vs. Vanilla Kubernetes - Key Differences","text":"<ul> <li> <p>Content: Deep dive into networking (AWS VPC CNI), IAM integration (IAM Roles for Service Accounts - IRSA), Load Balancing (AWS Load Balancer Controller), Authentication/Authorization, Upgrades.</p> </li> <li> <p>Estimated Time: 12 hours</p> </li> </ul>"},{"location":"#chapter-17-advanced-eks-operations-features","title":"Chapter 17: Advanced EKS Operations &amp; Features","text":"<ul> <li> <p>Content: Managed Node Groups vs. Fargate, Cluster Autoscaling (Cluster Autoscaler vs. Karpenter), Monitoring &amp; Logging integration (CloudWatch Container Insights), Security best practices on EKS.</p> </li> <li> <p>Estimated Time: 15 hours</p> </li> </ul>"},{"location":"#chapter-18-project-deploying-a-multi-tier-application-on-eks","title":"Chapter 18: Project - Deploying a Multi-Tier Application on EKS","text":"<ul> <li> <p>Content: Containerize an application, write Kubernetes manifests (Deployments, Services, Ingress), configure IRSA, deploy using <code>kubectl</code> or Helm, set up monitoring and auto-scaling (implementing Karpenter). Highlight EKS-specific configurations.</p> </li> <li> <p>Estimated Time: 25 hours</p> </li> </ul> <p>Total Estimated Course Time: Approximately 240 - 250 hours (Studying 1-2 hours per day, the course would take approximately 120-250 days to complete)</p> <p>(Note: These are estimates and actual time may vary based on the individual's learning pace and prior experience.)</p>"},{"location":"module_1/chapter_1/","title":"Chapter 1: (Python) Deep Dive &amp; Idiomatic Code","text":"<p>Estimated Time: 10 hours</p> <p>Goal: To solidify understanding of fundamental Python concepts and introduce advanced features, focusing on writing clean, efficient, and \"Pythonic\" code.</p>"},{"location":"module_1/chapter_1/#11-data-structures-control-flow","title":"1.1 Data Structures &amp; Control Flow","text":"<ul> <li> <p>Objective: Quickly refresh core data structures and control flow mechanisms.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>Lists: Methods (<code>append</code>, <code>extend</code>, <code>insert</code>, <code>remove</code>, <code>pop</code>, <code>sort</code>), slicing, list comprehensions (brief intro - covered more in 1.8).</p> </li> <li> <p>Dictionaries: Key-value pairs, methods (<code>keys</code>, <code>values</code>, <code>items</code>, <code>get</code>, <code>pop</code>), dictionary comprehensions (brief intro).</p> </li> <li> <p>Sets: Unordered unique elements, methods (<code>add</code>, <code>remove</code>, <code>union</code>, <code>intersection</code>, <code>difference</code>), use cases (membership testing, removing duplicates).</p> </li> <li> <p>Tuples: Immutable sequences, packing/unpacking, use cases (dictionary keys, returning multiple values).</p> </li> <li> <p>Control Flow: <code>if</code>/<code>elif</code>/<code>else</code>, <code>for</code> loops (iterating over sequences, <code>range</code>), <code>while</code> loops, <code>break</code>, <code>continue</code>, <code>pass</code>.</p> </li> </ul> </li> <li> <p>Example Snippet (Tuple Unpacking):</p> <pre><code># --- Example 1: Basic Tuple Unpacking ---\npoint = (10, 20)\nx, y = point # Unpacking\nprint(f\"x: {x}, y: {y}\")\n\n# --- Example 2: Unpacking in Loops ---\ncoordinates = [(0, 0), (1, 1), (2, 4)]\nfor x_coord, y_coord in coordinates: # Unpacking in loops\n    print(f\"Processing point: ({x_coord}, {y_coord})\")\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#12-functions-deep-dive","title":"1.2 Functions Deep Dive","text":"<ul> <li> <p>Objective: Understand function scope rules, closures, and flexible argument handling.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>Scope (LEGB Rule): Local, Enclosing function locals, Global, Built-in. How Python searches for names.</p> </li> <li> <p>Closures: Functions that \"remember\" their enclosing lexical scope, even when the enclosing function has finished executing. Practical examples (e.g., factory functions).</p> </li> <li> <p>Argument Packing/Unpacking:</p> <ul> <li> <p><code>*args</code>: Collects positional arguments into a tuple.</p> </li> <li> <p><code>**kwargs</code>: Collects keyword arguments into a dictionary.</p> </li> <li> <p>Using <code>*</code> and <code>**</code> when calling functions to unpack iterables/dictionaries.</p> </li> </ul> </li> </ul> </li> <li> <p>Example Snippet (Closure &amp; *args/kwargs):**</p> <pre><code># --- Example 1: Closure ---\ndef outer_function(msg):\n    # msg is in the enclosing scope\n    def inner_function():\n        # inner_function \"closes over\" msg\n        print(msg)\n    return inner_function # Return the inner function\n\nhello_func = outer_function(\"Hello\")\nhello_func() # Output: Hello\n\n# --- Example 2: *args and **kwargs ---\ndef process_data(id, *values, **options):\n    print(f\"Processing ID: {id}\")\n    print(f\"Values: {values}\") # Tuple\n    print(f\"Options: {options}\") # Dictionary\n    if options.get(\"verbose\", False):\n         print(\"Verbose mode enabled.\")\n\nprocess_data(101, 'a', 'b', 'c', verbose=True, retries=3)\n# Output:\n# Processing ID: 101\n# Values: ('a', 'b', 'c')\n# Options: {'verbose': True, 'retries': 3}\n# Verbose mode enabled.\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#13-object-oriented-programming-oop-revisited","title":"1.3 Object-Oriented Programming (OOP) Revisited","text":"<ul> <li> <p>Objective: Solidify OOP concepts and understand the role of special (\"dunder\") methods.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>Classes and Objects: Review of basic definition, instantiation.</p> </li> <li> <p>Inheritance: Single and multiple inheritance (Method Resolution Order - MRO), <code>super()</code>.</p> </li> <li> <p>Polymorphism: Duck typing (\"If it walks like a duck and quacks like a duck...\").</p> </li> <li> <p>Encapsulation: Using naming conventions (<code>_protected</code>, <code>__private</code> name mangling) - Python relies on convention more than strict enforcement.</p> </li> <li> <p>Dunder Methods:</p> <ul> <li> <p><code>__init__(self, ...)</code>: Constructor.</p> </li> <li> <p><code>__str__(self)</code>: User-friendly string representation (<code>str()</code>).</p> </li> <li> <p><code>__repr__(self)</code>: Developer-friendly string representation (<code>repr()</code>). Aim for unambiguous representation.</p> </li> <li> <p><code>__len__(self)</code>: Length (<code>len()</code>).</p> </li> <li> <p><code>__eq__(self, other)</code>: Equality comparison (<code>==</code>).</p> </li> <li> <p>Others (<code>__add__</code>, <code>__getitem__</code>, etc.) as needed.</p> </li> </ul> </li> <li> <p>Properties: Using <code>@property</code> decorator for getter methods, <code>@&lt;property_name&gt;.setter</code> for setters - provides controlled access to attributes.</p> </li> </ul> </li> <li> <p>Example Snippet (Inheritance, Dunder Methods &amp; Properties Combined):</p> <pre><code># --- Example Combined OOP Concepts ---\n\n# Base Class: Publication\nclass Publication:\n    \"\"\"Represents a generic publication with a title and price.\"\"\"\n    def __init__(self, title, price):\n        self.title = title\n        self._price = price # Use underscore for intended protected attribute\n\n    @property\n    def price(self):\n        \"\"\"Getter for the price using property decorator.\"\"\"\n        # Could add logic here, e.g., currency conversion\n        return self._price\n\n    @price.setter\n    def price(self, value):\n        \"\"\"Setter for the price with validation.\"\"\"\n        if value &lt; 0:\n            raise ValueError(\"Price cannot be negative.\")\n        self._price = value\n\n    # Dunder method for user-friendly string representation\n    def __str__(self):\n        return f\"{self.title} (Price: ${self.price:.2f})\"\n\n    # Dunder method for developer-friendly representation\n    def __repr__(self):\n        # Should ideally be unambiguous and allow recreating the object\n        return f\"{self.__class__.__name__}(title='{self.title}', price={self.price})\"\n\n    # Dunder method for equality comparison\n    def __eq__(self, other):\n        if not isinstance(other, Publication):\n            return NotImplemented # Indicate comparison not supported for this type\n        # Compare based on title and price for this example\n        return self.title == other.title and self.price == other.price\n\n# Derived Class: Book (inherits from Publication)\nclass Book(Publication):\n    \"\"\"Represents a book, inheriting from Publication and adding an author.\"\"\"\n    def __init__(self, title, author, price):\n        # Call the parent class's __init__ method using super()\n        super().__init__(title, price)\n        self.author = author\n\n    # Override __str__ to include the author\n    def __str__(self):\n        # Reuse parent's __str__ or format differently\n        # return f'\"{self.title}\" by {self.author} (Price: ${self.price:.2f})'\n        # Alternative: Reuse parent's logic via super() if desired, then add more\n        base_str = super().__str__()\n        return f'\"{self.title}\" by {self.author} - [{base_str}]'\n\n\n    # Override __repr__ to include the author\n    def __repr__(self):\n        # Recreate the specific Book object\n        return f\"Book(title='{self.title}', author='{self.author}', price={self.price})\"\n\n    # Override __eq__ to include author comparison\n    def __eq__(self, other):\n        if not isinstance(other, Book):\n            return NotImplemented\n        # Use parent's __eq__ via super() for title/price and add author check\n        return super().__eq__(other) and self.author == other.author\n\n    # Method specific to Book\n    def read_excerpt(self):\n        print(f\"Reading an excerpt from '{self.title}' by {self.author}...\")\n\n\n# --- Example Usage: Combined Concepts ---\nprint(\"--- Creating Instances ---\")\ngeneric_pub = Publication(\"Generic Magazine\", 5.99)\nbook1 = Book(\"The Pragmatic Programmer\", \"Andy Hunt\", 29.95)\nbook2 = Book(\"Clean Code\", \"Robert C. Martin\", 35.50)\nbook3 = Book(\"The Pragmatic Programmer\", \"Andy Hunt\", 29.95) # Same as book1\n\nprint(\"\\n--- Testing Dunder Methods (__str__, __repr__) ---\")\nprint(f\"Generic Pub (__str__): {generic_pub}\")\nprint(f\"Book 1 (__str__):      {book1}\")\nprint(f\"Generic Pub (__repr__): {repr(generic_pub)}\")\nprint(f\"Book 1 (__repr__):      {repr(book1)}\")\n\nprint(\"\\n--- Testing Property ---\")\nprint(f\"Book 1 original price: ${book1.price:.2f}\") # Getter\nbook1.price = 32.00 # Setter\nprint(f\"Book 1 new price: ${book1.price:.2f}\")\ntry:\n    book1.price = -10 # Setter validation\nexcept ValueError as e:\n    print(f\"Error setting price: {e}\")\n\nprint(\"\\n--- Testing Inheritance &amp; Overriding ---\")\nbook1.read_excerpt() # Method specific to Book\n# generic_pub.read_excerpt() # Would cause AttributeError\n\nprint(\"\\n--- Testing Equality (__eq__) ---\")\nprint(f\"book1 == book2: {book1 == book2}\") # False\nprint(f\"book1 == book3: {book1 == book3}\") # True\nprint(f\"book1 == generic_pub: {book1 == generic_pub}\") # False (different types handled by isinstance check)\n\nprint(\"\\n--- Testing isinstance ---\")\nprint(f\"Is book1 a Book? {isinstance(book1, Book)}\")           # True\nprint(f\"Is book1 a Publication? {isinstance(book1, Publication)}\") # True\nprint(f\"Is generic_pub a Book? {isinstance(generic_pub, Book)}\") # False\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#14-decorators","title":"1.4 Decorators","text":"<ul> <li> <p>Objective: Understand how decorators work conceptually, why they are useful, and how to implement custom ones for common tasks like logging or timing.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>What are Decorators? Syntactic sugar (<code>@</code>) for a pattern where a function takes another function as input, adds some functionality (wraps it), and returns the modified function. Think of it like wrapping a gift \u2013 you add wrapping paper (extra functionality) without changing the gift (original function) itself.</p> </li> <li> <p>Why Use Decorators?</p> <ul> <li> <p>Code Reusability: Apply the same extra logic (like logging, timing, access control) to multiple functions without repeating code.</p> </li> <li> <p>Separation of Concerns: Keep the core logic of your function separate from cross-cutting concerns (like logging or performance monitoring).</p> </li> <li> <p>Readability: The <code>@decorator_name</code> syntax clearly indicates that a function's behavior is being modified.</p> </li> </ul> </li> <li> <p>Functions as First-Class Objects: Decorators rely on the fact that functions in Python can be passed as arguments, returned from other functions, and assigned to variables.</p> </li> <li> <p>How Decorators Work (Conceptual Steps):</p> <ol> <li> <p>You define a function (e.g., <code>my_decorator</code>) that accepts another function (<code>func</code>) as an argument.</p> </li> <li> <p>Inside <code>my_decorator</code>, you define a nested function (often called <code>wrapper</code> or <code>inner</code>). This <code>wrapper</code> function will contain the extra logic plus a call to the original function <code>func</code>.</p> </li> <li> <p><code>my_decorator</code> returns the <code>wrapper</code> function.</p> </li> <li> <p>When you use <code>@my_decorator</code> above another function definition (e.g., <code>say_hello</code>), Python essentially does this: <code>say_hello = my_decorator(say_hello)</code>. Now, <code>say_hello</code> actually refers to the <code>wrapper</code> function returned by the decorator.</p> </li> </ol> </li> <li> <p>Using <code>functools.wraps</code>: Essential for preserving the original function's metadata (like its name <code>__name__</code> and docstring <code>__doc__</code>). Without it, the decorated function would appear to be the <code>wrapper</code> function, which can confuse debugging and documentation tools.</p> </li> <li> <p>Decorators with Arguments: Requires an extra layer of nesting. The outer function takes the decorator arguments and returns the actual decorator function, which then takes the target function and returns the wrapper.</p> </li> <li> <p>Class-Based Decorators: You can also use classes to create decorators, typically by implementing the <code>__init__</code> and <code>__call__</code> methods. The instance is initialized, and then <code>__call__</code> is invoked when the decorated function is called.</p> </li> </ul> </li> <li> <p>Example Snippet (Simple Timer Decorator - Explained):</p> <pre><code># --- Example 1: Timer Decorator ---\nimport functools\nimport time\n\n# 1. Define the decorator function: takes the target function 'func'\ndef timer(func):\n    # 3. Use functools.wraps to copy metadata from 'func' to 'wrapper'\n    @functools.wraps(func)\n    # 2. Define the inner 'wrapper' function: takes the same args as 'func'\n    def wrapper(*args, **kwargs):\n        print(f\"Entering {func.__name__!r}...\") # Added entry log\n        start_time = time.perf_counter()\n        # 4. Call the original function 'func' with its arguments\n        result = func(*args, **kwargs)\n        end_time = time.perf_counter()\n        run_time = end_time - start_time\n        print(f\"Finished {func.__name__!r} in {run_time:.4f} secs\") # Original timing log\n        # 5. Return the result of the original function\n        return result\n    # 6. The decorator returns the 'wrapper' function\n    return wrapper\n\n# 7. Apply the decorator using @ syntax\n@timer\ndef complex_calculation(n):\n    \"\"\"Simulates a time-consuming task.\"\"\"\n    total = 0\n    for i in range(n):\n        total += i*i\n    return total\n\n# 8. Calling complex_calculation now actually calls the 'wrapper'\nresult = complex_calculation(1000000)\n# Output:\n# Entering 'complex_calculation'...\n# Finished 'complex_calculation' in X.XXXX secs (time will vary)\n\nprint(f\"Result: {result}\")\nprint(complex_calculation.__name__) # Output: complex_calculation (thanks to wraps)\nprint(complex_calculation.__doc__) # Output: Simulates a time-consuming task. (thanks to wraps)\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#15-generators-and-iterators","title":"1.5 Generators and Iterators","text":"<ul> <li> <p>Objective: Learn how generators provide memory-efficient ways to create iterables, especially for large datasets.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>Iterator Protocol: Defines how iteration works via <code>__iter__()</code> (returns the iterator object itself) and <code>__next__()</code> (returns the next item). <code>StopIteration</code> exception is raised when no more items are available.</p> </li> <li> <p>Generators: Functions using <code>yield</code> to produce a sequence of values lazily. State is saved between calls.</p> </li> <li> <p>Generator Expressions: Concise syntax similar to list comprehensions but creating generators <code>(x*x for x in range(10))</code>.</p> </li> <li> <p>Use cases: Processing large files, infinite sequences, pipelines.</p> </li> </ul> </li> <li> <p>Example Snippet (Generator for Fibonacci):</p> <pre><code># --- Example 1: Fibonacci Generator ---\ndef fibonacci_generator(limit):\n    a, b = 0, 1\n    while a &lt; limit:\n        yield a # Pauses execution and returns value\n        a, b = b, a + b # Resumes here on next call\n\n# Using the generator\nprint(\"Fibonacci sequence:\")\nfor number in fibonacci_generator(100):\n    print(number, end=\" \") # Output: 0 1 1 2 3 5 8 13 21 34 55 89\nprint(\"\\n\")\n\n# --- Example 2: Generator Expression ---\nsquares = (x*x for x in range(5))\nprint(type(squares)) # &lt;class 'generator'&gt;\nfor sq in squares:\n    print(sq, end=\" \") # Output: 0 1 4 9 16\nprint()\n</code></pre> </li> <li> <p>Example Snippet (Simple Generator Pipeline):</p> <pre><code># --- Example 3: Simple Generator Pipeline ---\n# 0. Our initial data\nnumbers = [1, 2, 3, 4, 5, 6, 7, 8]\n\n# 1. First pipeline step: Square the numbers\ndef square_numbers(nums):\n  for n in nums:\n    yield n * n\n\n# 2. Second pipeline step: Filter for even numbers\ndef filter_even(squared_nums):\n  for n in squared_nums:\n    if n % 2 == 0:\n      yield n\n\n# 3. Build the pipeline by chaining the generators\npipeline = filter_even(square_numbers(numbers))\n\n# 4. Pull data through the pipeline\nprint(\"Starting pipeline execution...\")\nfor even_square in pipeline:\n  print(f\"PIPELINE RESULT: {even_square}\")\nprint(\"Pipeline finished.\")\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#16-context-managers","title":"1.6 Context Managers","text":"<ul> <li> <p>Objective: Understand how the <code>with</code> statement simplifies resource management (files, network connections, locks).</p> </li> <li> <p>Topics:</p> <ul> <li> <p>The need for cleanup (<code>try...finally</code>): Manually managing resources (like closing files or releasing locks) with <code>try...finally</code> is necessary but verbose and error-prone; it's easy to forget the <code>finally</code> block or handle exceptions incorrectly.</p> </li> <li> <p>The <code>with</code> statement: Provides a cleaner, more reliable way to ensure that setup and teardown actions (like opening/closing a resource) happen automatically, even if errors occur within the block.</p> </li> <li> <p>Context Manager Protocol: This is what makes the <code>with</code> statement work. Requires an object to have two special methods:</p> <ul> <li> <p><code>__enter__(self)</code>: Executed at the start of the <code>with</code> block. Often returns the resource itself (like the file object) or <code>self</code>.</p> </li> <li> <p><code>__exit__(self, exc_type, exc_val, exc_tb)</code>: Executed when exiting the <code>with</code> block (normally or due to an exception). It receives exception details (type, value, traceback) if any occurred and performs the cleanup. Returning <code>True</code> from <code>__exit__</code> suppresses the exception.</p> </li> </ul> </li> <li> <p>Using <code>contextlib.contextmanager</code>: A decorator that lets you create a context manager more easily using a generator function with a single <code>yield</code>. Code before <code>yield</code> acts as <code>__enter__</code>, code after <code>yield</code> (in a <code>finally</code> block) acts as <code>__exit__</code>.</p> </li> </ul> </li> <li> <p>Example Snippet (File Handling &amp; Custom Context Manager):</p> <pre><code># --- Example 1: Standard file handling with 'with' ---\ntry:\n    with open(\"example.txt\", \"w\") as f:\n        f.write(\"Hello, context managers!\\n\")\n        # Simulate an error\n        # raise ValueError(\"Something went wrong\")\n    # File is automatically closed here, even if an error occurs inside the block\n    print(\"File 'example.txt' written and closed.\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n    # File is still closed if it was opened\n\n# --- Example 2: Custom context manager using contextlib ---\nimport contextlib\nimport time\n\n@contextlib.contextmanager\ndef simple_timer(label=\"Execution\"):\n    \"\"\"A simple context manager to time a block of code.\"\"\"\n    start = time.perf_counter()\n    try:\n        yield # Execution pauses here, control goes to the 'with' block\n    finally:\n        # Cleanup code runs regardless of exceptions in the 'with' block\n        end = time.perf_counter()\n        print(f\"{label} took {end - start:.4f} seconds\")\n\n# Using the custom timer context manager\nwith simple_timer(\"Block Timer\"):\n    print(\"Inside the timed block...\")\n    time.sleep(0.5) # Simulate work\n    print(\"...block finished.\")\n\n# Expected Output:\n# File 'example.txt' written and closed.\n# Inside the timed block...\n# ...block finished.\n# Block Timer took 0.5XXX seconds\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#17-advanced-error-handling","title":"1.7 Advanced Error Handling","text":"<ul> <li> <p>Objective: Learn to create and use custom exceptions for more specific error reporting.</p> </li> <li> <p>Topics:</p> <ul> <li> <p><code>try...except</code>: The fundamental block for handling errors. Code that might raise an exception goes in the <code>try</code> part, and code to run if a specific error occurs goes in the <code>except</code> part.</p> </li> <li> <p>Handling specific exception types vs. broad <code>Exception</code>: It's best practice to catch specific errors you anticipate (like <code>ValueError</code> or <code>FileNotFoundError</code>). Catching a broad <code>Exception</code> can hide bugs or catch errors you didn't intend to handle (like <code>SystemExit</code> or <code>KeyboardInterrupt</code>), making debugging harder.</p> </li> <li> <p><code>else</code> block: Code that runs only if no exceptions occurred in the <code>try</code> block.</p> </li> <li> <p><code>finally</code> block: Code that runs always (cleanup).</p> </li> <li> <p><code>raise</code> is used to raise Exceptions.</p> </li> <li> <p>Custom exception classes can be created inheriting from <code>Exception</code> or more specific built-ins.</p> </li> <li> <p>Chaining exceptions (<code>raise NewException from original_exception</code>): This preserves the original error context, making it easier to debug the root cause when wrapping exceptions.</p> </li> </ul> </li> <li> <p>Example Snippet (Custom Exception &amp; Chaining):</p> <pre><code># --- Example 1: Custom Exception &amp; Chaining ---\nclass InsufficientFundsError(Exception):\n    \"\"\"Custom exception for bank account operations.\"\"\"\n    def __init__(self, requested, available):\n        self.requested = requested\n        self.available = available\n        super().__init__(f\"Attempted to withdraw {requested}, but only {available} available.\")\n\ndef withdraw(balance, amount):\n    \"\"\"Withdraws amount if possible, raises errors otherwise.\"\"\"\n    if amount &lt;= 0:\n        raise ValueError(\"Withdrawal amount must be positive.\")\n    if amount &gt; balance:\n        # Example of raising a custom exception\n        raise InsufficientFundsError(requested=amount, available=balance)\n    return balance - amount\n\ndef process_withdrawal(balance, amount):\n    \"\"\"Processes withdrawal, demonstrating exception chaining.\"\"\"\n    try:\n        return withdraw(balance, amount)\n    except InsufficientFundsError as e:\n        print(\"Logging insufficient funds event...\")\n        # Raise a more general processing error, but link it to the original cause\n        raise RuntimeError(f\"Withdrawal processing failed for amount {amount}\") from e\n    except ValueError as e:\n         print(\"Logging invalid amount event...\")\n         # Raise a more general processing error, linking to the original cause\n         raise RuntimeError(f\"Invalid withdrawal amount: {amount}\") from e\n\n\naccount_balance = 100\ntry:\n    print(\"Attempting withdrawal processing...\")\n    # account_balance = process_withdrawal(account_balance, 150) # Example for InsufficientFundsError\n    account_balance = process_withdrawal(account_balance, -50) # Example for ValueError -&gt; RuntimeError\n    print(\"Withdrawal successful.\") # This won't run if error occurs\nexcept RuntimeError as e:\n     print(f\"Caught Processing Error: {e}\")\n     if e.__cause__:\n         print(f\"  --&gt; Original Cause: {type(e.__cause__).__name__}: {e.__cause__}\") # Show the chained exception\nexcept Exception as e:\n    print(f\"An unexpected error occurred: {type(e).__name__}: {e}\") # Less specific, use sparingly\nelse:\n    print(\"Transaction completed without errors.\") # Runs only if try succeeds\nfinally:\n    print(f\"Current balance: {account_balance}\") # Runs always\n\n# Example Output (for amount = -50):\n# Attempting withdrawal processing...\n# Logging invalid amount event...\n# Caught Processing Error: Invalid withdrawal amount: -50\n#   --&gt; Original Cause: ValueError: Withdrawal amount must be positive.\n# Current balance: 100\n\n# Example Output (for amount = 150):\n# Attempting withdrawal processing...\n# Logging insufficient funds event...\n# Caught Processing Error: Withdrawal processing failed for amount 150\n#   --&gt; Original Cause: InsufficientFundsError: Attempted to withdraw 150, but only 100 available.\n# Current balance: 100\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#18-pythonic-code","title":"1.8 Pythonic Code","text":"<ul> <li> <p>Objective: Embrace Python's idioms for more readable, concise, and efficient code.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>List Comprehensions: <code>[expr for item in iterable if condition]</code>.</p> </li> <li> <p>Dictionary Comprehensions: <code>{key_expr: val_expr for item in iterable if condition}</code>.</p> </li> <li> <p>Set Comprehensions: <code>{expr for item in iterable if condition}</code>.</p> </li> <li> <p>Generator Expressions: <code>(expr for item in iterable if condition)</code> - memory efficient, especially useful for large sequences or when you don't need the result list in memory.</p> </li> <li> <p>Using <code>enumerate</code> for index and value in loops.</p> </li> <li> <p>Using <code>zip</code> to iterate over multiple sequences simultaneously.</p> </li> <li> <p>Avoiding manual index manipulation in loops where possible.</p> </li> <li> <p>Truthy and Falsy values (checking for empty sequences/collections directly instead of using <code>len()</code>).</p> </li> <li> <p>f-Strings: Prefer f-strings (<code>f\"...\"</code>) for embedding expressions inside string literals, as they are generally the most concise and readable method.</p> </li> </ul> </li> <li> <p>Example Snippet (Pythonic Examples):</p> <pre><code># --- Example 1a: Non-Pythonic loop (Squaring) ---\nnumbers = [1, 2, 3, 4, 5]\nsquares = []\nfor i in range(len(numbers)):\n    squares.append(numbers[i] * numbers[i])\nprint(squares)\n\n# --- Example 1b: Pythonic using list comprehension (Squaring) ---\nsquares_comp = [n * n for n in numbers]\nprint(squares_comp)\n\n# --- Example 2a: Non-Pythonic filtering ---\nevens = []\nfor n in numbers:\n    if n % 2 == 0:\n        evens.append(n)\nprint(evens)\n\n# --- Example 2b: Pythonic filtering with list comprehension ---\nevens_comp = [n for n in numbers if n % 2 == 0]\nprint(evens_comp)\n\n# --- Example 3a: Iterating with index (less Pythonic) ---\nitems = ['a', 'b', 'c']\nfor i in range(len(items)):\n    print(f\"Index {i}: {items[i]}\")\n\n# --- Example 3b: Pythonic iteration with enumerate ---\nfor index, item in enumerate(items):\n    print(f\"Index {index}: {item}\")\n\n# --- Example 4: Checking for empty list (Pythonic) ---\nmy_list = []\nif not my_list: # Instead of if len(my_list) == 0:\n    print(\"List is empty\")\n\n# --- Example 5: Iterating with zip ---\nnames = [\"Alice\", \"Bob\", \"Charlie\"]\nscores = [85, 92, 78]\n# zip pairs corresponding elements from multiple iterables\nfor name, score in zip(names, scores):\n    print(f\"{name}: {score}\")\n# Stops when the shortest iterable is exhausted\n\n# --- Example 6a: Summing squares (less Pythonic - creates intermediate list) ---\nbig_numbers = range(1, 1000001) # Represents a potentially large sequence\n# Creates a potentially huge list in memory first\ntotal_sum_list = sum([x*x for x in big_numbers])\nprint(f\"Sum of squares (via list): {total_sum_list}\") # Works, but memory intensive\n\n# --- Example 6b: Summing squares (Pythonic - uses generator expression) ---\n# Creates items one by one as sum() consumes them - much more memory efficient\ntotal_sum_gen = sum(x*x for x in big_numbers)\nprint(f\"Sum of squares (via generator): {total_sum_gen}\")\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#19-style-guides-linters","title":"1.9 Style Guides &amp; Linters","text":"<ul> <li> <p>Objective: Understand the importance of consistent code style and how tools can help enforce it.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>Linters: Tools that analyze code for style errors and potential bugs (can be configured as pre-commit hooks).</p> <ul> <li> <p><code>Flake8</code>: Combines <code>PyFlakes</code> (error checking), <code>pycodestyle</code> (PEP 8 checking), and McCabe (complexity checking).</p> </li> <li> <p><code>Pylint</code>: More extensive checks, highly configurable, can be \"noisy\".</p> </li> </ul> </li> <li> <p>Formatters: Tools that automatically reformat code to comply with a style guide.</p> <ul> <li><code>Black</code>: The \"uncompromising code formatter\", enforces a strict subset of PEP 8.</li> </ul> </li> <li> <p>Integrating linters/formatters into development workflow (editor integration, pre-commit hooks).</p> </li> </ul> </li> <li> <p>Exercise: Install <code>flake8</code> and <code>black</code> (e.g., <code>pip install flake8 black</code>). Save the following code into a Python file (e.g., <code>style_practice.py</code>) and run <code>flake8 style_practice.py</code> to see the style/error reports. Then, run <code>black style_practice.py</code> to automatically format the code. Run <code>flake8</code> again to see the difference.</p> <pre><code># --- Code for Linter/Formatter Exercise ---\nimport sys\n\ndef my_func( a,b ):\n    '''A simple function with style issues.'''\n    if (a&gt;b): # Poor spacing\n        result=a*2\n    else:\n          result = b+1 # Bad indentation\n    unused_variable = \"I am not used\" # Flake8 should find this\n    really_long_line = \"This line is intentionally made very very very very very very very very very very very very long to exceed the typical line length limit.\"\n    return result\n\nx =10\ny= 5 # Missing space around operator\n\nprint (my_func( x,y )) # Extra space before parenthesis\n\n# Missing newline at end of file (Flake8 might warn)\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_1/#110-naming-conventions-and-code-readability","title":"1.10 Naming Conventions and Code Readability","text":"<ul> <li> <p>Objective: Emphasize the critical role of clear, descriptive naming in writing understandable code.</p> </li> <li> <p>Topics:</p> <ul> <li> <p>PEP 8 Naming Conventions:</p> <ul> <li> <p><code>lower_case_with_underscores</code> for functions, methods, variables (snake_case). Also for filenames.</p> </li> <li> <p><code>UPPER_CASE_WITH_UNDERSCORES</code> for constants.</p> </li> <li> <p><code>CapitalizedWords</code> (CamelCase or PascalCase) for classes.</p> </li> <li> <p><code>_leading_underscore</code>: Internal use/protected convention.</p> </li> <li> <p><code>__leading_double_underscore</code>: Name mangling for class attributes.</p> </li> <li> <p><code>__leading_and_trailing_double_underscore__</code>: \"Magic\" objects or attributes (dunders).</p> </li> </ul> </li> <li> <p>Choosing descriptive names: Avoid single letters (except simple loop counters), abbreviations, ambiguity. Name reflects purpose.</p> </li> <li> <p>Function/Method Naming: Often verbs or verb phrases (e.g., <code>calculate_total</code>, <code>is_valid</code>).</p> </li> <li> <p>Variable Naming: Often nouns or noun phrases (e.g., <code>user_name</code>, <code>total_count</code>).</p> </li> <li> <p>Boolean variables/functions: Often start with <code>is_</code>, <code>has_</code>, <code>should_</code> (e.g., <code>is_empty</code>, <code>has_permission</code>).</p> </li> <li> <p>Writing clear comments: Explain why, not what (if the code is already clear). Document complex logic or assumptions. Docstrings for functions/classes/modules.</p> </li> </ul> </li> </ul>"},{"location":"module_1/chapter_1_exercise/","title":"Chapter 1 Project: Refactoring and Enhancing a Data Processor","text":"<p>Goal: Apply the concepts learned in Chapter 1 (Pythonic code, OOP, error handling, context managers, decorators, testing) to refactor, extend, and test a simple data processing script.</p> <p>Scenario:</p> <p>You are given a Python script that reads employee data from a CSV file. Each row contains an employee ID, name, department, and salary. The script currently calculates the total salary expenditure and identifies the employee with the highest salary. However, the code is written in a somewhat procedural and less \"Pythonic\" style, lacks robust error handling, and has no tests.</p> <p>Initial Code (<code>data_processor_v0.py</code>):</p> <pre><code># --- Initial Code for Refactoring ---\n# (Save this as data_processor_v0.py)\n\nimport csv\n\ndef process_employee_data(filepath):\n    # Reads data, calculates total salary and finds highest earner\n\n    file = open(filepath, 'r')\n    reader = csv.reader(file)\n\n    header = next(reader) # Skip header row\n\n    total_salary = 0\n    highest_salary = -1\n    highest_earner_name = None\n\n    employee_data = []\n    for row in reader:\n        employee_data.append(row)\n\n    file.close()\n\n    i = 0\n    while i &lt; len(employee_data):\n        row = employee_data[i]\n        try:\n            emp_id = int(row[0])\n            name = row[1]\n            department = row[2]\n            salary = float(row[3])\n\n            total_salary = total_salary + salary\n\n            if salary &gt; highest_salary:\n                highest_salary = salary\n                highest_earner_name = name\n\n        except Exception as e:\n            print(\"Error processing row:\", row, \"Error:\", e)\n            # Potentially skips rows silently or with just a print\n\n        i = i + 1\n\n    print(\"Processing Complete.\")\n    print(\"Total Salary Expenditure:\", total_salary)\n    print(\"Highest Earner:\", highest_earner_name, \"with salary:\", highest_salary)\n\n    return total_salary, highest_earner_name\n\n# Example Usage (requires a sample 'employees.csv' file)\n# Create a file named 'employees.csv' with content like:\n# ID,Name,Department,Salary\n# 1,Alice,Engineering,90000\n# 2,Bob,Sales,80000\n# 3,Charlie,Engineering,95000\n# 4,David,HR,70000\n\n# total, highest_name = process_employee_data('employees.csv')\n</code></pre> <p>Sample <code>employees.csv</code>:</p> <pre><code>ID,Name,Department,Salary\n1,Alice,Engineering,90000\n2,Bob,Sales,80000\n3,Charlie,Engineering,95000\n4,David,HR,70000\n5,Eve,Sales,82000\n</code></pre> <p>Tasks:</p> <ol> <li> <p>Refactor the <code>process_employee_data</code> function to improve its style, readability, and efficiency. Consider aspects like resource management, iteration, data handling, code structure, data access, and error handling.</p> </li> <li> <p>Extend the script's functionality by adding robust error handling, logging capabilities, and a new calculation for average salary per department.</p> </li> <li> <p>Implement unit tests for the core processing logic using <code>unittest</code> or <code>pytest</code>.</p> </li> </ol> <p>Hints &amp; Potential Solution Approaches:</p> <ul> <li> <p>Task 1 (Refactoring):</p> <ul> <li> <p>Use a <code>with</code> statement for file handling.</p> </li> <li> <p>Iterate directly over the <code>csv.reader</code> object instead of creating an intermediate <code>employee_data</code> list.</p> </li> <li> <p>Consider representing each row using a dictionary, <code>collections.namedtuple</code>, or a custom <code>Employee</code> class.</p> </li> <li> <p>Access data fields by name (e.g., <code>row['Salary']</code> or <code>employee.salary</code>) instead of index (<code>row[3]</code>).</p> </li> <li> <p>Look for opportunities to use list/generator comprehensions.</p> </li> <li> <p>Apply PEP 8 naming (<code>snake_case</code>) and formatting (<code>black</code>).</p> </li> </ul> </li> <li> <p>Task 2 (Extending):</p> <ul> <li> <p>Use <code>try...except</code> blocks to catch specific exceptions like <code>FileNotFoundError</code>, <code>ValueError</code>, <code>TypeError</code>, <code>IndexError</code>.</p> </li> <li> <p>Implement a clear strategy for handling rows with errors (e.g., logging the error and skipping the row).</p> </li> <li> <p>Use the <code>logging</code> module for informative messages (e.g., file processing start/end, errors encountered). A simple logging decorator could also be used.</p> </li> <li> <p>To calculate average salary per department, use a dictionary to accumulate total salaries and counts for each department encountered during iteration.</p> </li> </ul> </li> <li> <p>Task 3 (Testing):</p> <ul> <li> <p>Create test functions for <code>test_total_salary</code>, <code>test_highest_earner</code>, <code>test_average_salary_per_department</code>.</p> </li> <li> <p>Use <code>unittest.mock</code> or <code>pytest</code> fixtures/mocks to simulate file reading or pass in sample data structures (lists of lists, lists of dicts, etc.) directly to your refactored processing logic.</p> </li> <li> <p>Include tests for edge cases: empty input, input with only headers, rows with missing data, rows with non-numeric salaries.</p> </li> </ul> </li> </ul> <p>Concepts to Apply from Chapter 1:</p> <ul> <li> <p>Context Managers (<code>with</code> statement)</p> </li> <li> <p>Pythonic Loops (<code>for</code>, list/generator comprehensions, <code>enumerate</code>, <code>zip</code> if applicable)</p> </li> <li> <p>Functions (<code>*args</code>, <code>**kwargs</code> might be useful if refactoring)</p> </li> <li> <p>OOP (Consider using a class for <code>Employee</code> or the processor itself)</p> </li> <li> <p>Dunder Methods (If creating classes, implement <code>__init__</code>, <code>__repr__</code>, etc.)</p> </li> <li> <p>Properties (If using classes with controlled attribute access)</p> </li> <li> <p>Decorators (Optional, but useful for logging or timing)</p> </li> <li> <p>Generators/Iterators (Reading CSV row by row is inherently iterator-based)</p> </li> <li> <p>Advanced Error Handling (<code>try...except SpecificError</code>, <code>else</code>, <code>finally</code>, custom exceptions if desired)</p> </li> <li> <p>PEP 8 Styling &amp; Linters/Formatters (<code>flake8</code>, <code>black</code>)</p> </li> <li> <p>Clear Naming Conventions</p> </li> </ul>"},{"location":"module_1/chapter_1_quiz/","title":"Chapter 1 Quiz: Python Deep Dive &amp; Best Practices","text":"<p>Select the best answer for each question.</p>"},{"location":"module_1/chapter_1_quiz/#question-1","title":"Question 1","text":"<p>Consider the following code:</p> <pre><code>def my_decorator(func):\n    def wrapper(*args, **kwargs):\n        print(\"Before\")\n        result = func(*args, **kwargs)\n        print(\"After\")\n        return result\n    return wrapper\n\n@my_decorator\ndef say_whee(name=\"World\"):\n    print(f\"Whee, {name}!\")\n\nsay_whee(\"Pythonista\")\n</code></pre> <p>What will be the exact output when <code>say_whee(\"Pythonista\")</code> is called?</p> <p>a. <pre><code>Whee, Pythonista!\n</code></pre></p> <p>b. <pre><code>Before\nAfter\n</code></pre></p> <p>c. <pre><code>Before\nWhee, Pythonista!\nAfter\n</code></pre></p> <p>d. <pre><code>Whee, Pythonista!\nBefore\nAfter\n</code></pre></p> Click to see the answer <p>The correct answer is c). The decorator's <code>wrapper</code> function executes first, printing \"Before\". Then, it calls the original <code>say_whee</code> function, which prints \"Whee, Pythonista!\". Finally, the <code>wrapper</code> function continues after the original function call and prints \"After\".</p>"},{"location":"module_1/chapter_1_quiz/#question-2","title":"Question 2","text":"<p>Which pair of special methods correctly represents the core of the Context Manager Protocol, and what are their primary roles?</p> <p>a. <code>__init__</code> (for setup) and <code>__del__</code> (for cleanup) b. <code>__enter__</code> (for setup) and <code>__exit__</code> (for cleanup) c. <code>__call__</code> (for setup) and <code>__next__</code> (for cleanup) d. <code>__iter__</code> (for setup) and <code>__yield__</code> (for cleanup)</p> Click to see the answer <p>The correct answer is b). The <code>with</code> statement relies on the <code>__enter__</code> method to perform setup actions when entering the block and the <code>__exit__</code> method to perform cleanup actions when exiting the block.</p>"},{"location":"module_1/chapter_1_quiz/#question-3","title":"Question 3","text":"<p>When processing a very large sequence of numbers (e.g., millions of items), why is using a generator expression like <code>sum(x*x for x in large_sequence)</code> generally preferred over a list comprehension like <code>sum([x*x for x in large_sequence])</code>?</p> <p>a. Generator expressions are always faster than list comprehensions. b. Generator expressions use significantly less memory because they generate items one by one, avoiding the creation of a large intermediate list. c. List comprehensions cannot handle sequences with more than a few thousand items. d. Generator expressions automatically handle errors within the sequence, while list comprehensions do not.</p> Click to see the answer <p>The correct answer is b). The main advantage of generator expressions in this scenario is memory efficiency. They produce items lazily (one at a time as needed by the <code>sum()</code> function), whereas the list comprehension creates the entire list of squared numbers in memory first, which can be problematic for very large sequences.</p>"},{"location":"module_1/chapter_1_quiz/#question-4","title":"Question 4","text":"<p>Consider the following Python code involving nested functions (closures):</p> <pre><code>x = \"Global\"\n\ndef outer_func():\n    x = \"Enclosing Original\"\n    def inner_func():\n        print(f\"Inner sees: {x}\")\n\n    x = \"Enclosing Modified\"\n    inner_func()\n\nouter_func()\n</code></pre> <p>What will be printed when <code>outer_func()</code> is called?</p> <p>a. Inner sees: Global b. Inner sees: Enclosing Original c. Inner sees: Enclosing Modified d. An error will occur because <code>x</code> was changed after <code>inner_func</code> was defined.</p> Click to see the answer <p>The correct answer is c). Closures in Python capture variables by reference, not by their value at the time the inner function is defined. When <code>inner_func</code> is eventually called, it looks up the current value of <code>x</code> in its enclosing scope (<code>outer_func</code>). Since <code>x</code> in <code>outer_func</code> was changed to \"Enclosing Modified\" before <code>inner_func</code> was called, that's the value it prints.</p>"},{"location":"module_1/chapter_1_quiz/#question-5","title":"Question 5","text":"<p>What is the primary purpose of the <code>*args</code> parameter in a function definition like <code>def func(a, b, *args):</code>?</p> <p>a. To collect all keyword arguments into a dictionary. b. To specify required positional arguments. c. To collect any additional positional arguments passed to the function into a tuple. d. To indicate that the function is a generator.</p> Click to see the answer <p>The correct answer is c). <code>*args</code> allows a function to accept an arbitrary number of positional arguments beyond the explicitly named ones, collecting them into a tuple named <code>args</code>.</p>"},{"location":"module_1/chapter_1_quiz/#question-6","title":"Question 6","text":"<p>In object-oriented programming, what does <code>super().__init__(...)</code> typically do inside the <code>__init__</code> method of a derived class?</p> <p>a. It creates an instance of the superclass. b. It calls the <code>__init__</code> method of the parent class (superclass) to initialize the inherited attributes. c. It prevents the parent class's <code>__init__</code> from being called. d. It checks if the object is an instance of the superclass.</p> Click to see the answer <p>The correct answer is b). <code>super()</code> provides a way to call methods defined in the parent class(es), and <code>super().__init__(...)</code> is commonly used to ensure the initialization logic of the parent class is executed.</p>"},{"location":"module_1/chapter_1_quiz/#question-7","title":"Question 7","text":"<p>What is the main difference in intended use between the <code>__str__</code> and <code>__repr__</code> dunder methods?</p> <p>a. <code>__str__</code> is for debugging, <code>__repr__</code> is for user display. b. <code>__str__</code> should return a user-friendly string representation, while <code>__repr__</code> should return an unambiguous, developer-focused representation (ideally one that could recreate the object). c. <code>__str__</code> is called by <code>print()</code>, <code>__repr__</code> is called by <code>str()</code>. d. There is no significant difference; they are interchangeable.</p> Click to see the answer <p>The correct answer is b). <code>str()</code> (and <code>print</code>) defaults to <code>__str__</code> if available, aiming for readability. <code>repr()</code> defaults to <code>__repr__</code>, aiming for an unambiguous representation useful for developers.</p>"},{"location":"module_1/chapter_1_quiz/#question-8","title":"Question 8","text":"<p>Why is using the <code>@property</code> decorator often preferred over exposing attributes directly (e.g., using <code>my_object.value = 10</code>)?</p> <p>a. It makes attribute access significantly faster. b. It allows you to add logic (like validation or computation) to the getting or setting of an attribute while maintaining a simple attribute access syntax. c. It is required for attributes used in dunder methods. d. It automatically makes attributes read-only.</p> Click to see the answer <p>The correct answer is b). Properties allow you to control access, add validation, or compute values when an attribute is accessed or modified, without changing the external syntax <code>object.attribute</code>.</p>"},{"location":"module_1/chapter_1_quiz/#question-9","title":"Question 9","text":"<p>What problem does <code>functools.wraps</code> solve when writing decorators?</p> <p>a. It makes the decorated function run faster. b. It allows decorators to accept arguments. c. It prevents the decorator from executing. d. It preserves the original function's metadata (like <code>__name__</code> and <code>__doc__</code>) on the wrapped function.</p> Click to see the answer <p>The correct answer is d). Without <code>functools.wraps</code>, the decorated function would appear to have the name and docstring of the inner <code>wrapper</code> function, which can be confusing for debugging and introspection. <code>wraps</code> copies this metadata from the original function to the wrapper.</p>"},{"location":"module_1/chapter_1_quiz/#question-10","title":"Question 10","text":"<p>Which keyword is essential for defining a generator function in Python?</p> <p>a. <code>generate</code> b. <code>return</code> c. <code>yield</code> d. <code>next</code></p> Click to see the answer <p>The correct answer is c). The presence of the <code>yield</code> keyword in a function definition automatically makes it a generator function. It yields values one at a time instead of returning a single value.</p>"},{"location":"module_1/chapter_1_quiz/#question-11","title":"Question 11","text":"<p>What exception is raised by an iterator's <code>__next__</code> method to signal that there are no more items to iterate over?</p> <p>a. <code>IndexError</code> b. <code>StopIteration</code> c. <code>EndOfStreamError</code> d. <code>ValueError</code></p> Click to see the answer <p>The correct answer is b). The <code>StopIteration</code> exception is the standard way the iterator protocol signals the end of the sequence. <code>for</code> loops automatically handle this exception.</p>"},{"location":"module_1/chapter_1_quiz/#question-12","title":"Question 12","text":"<p>If an exception occurs inside a <code>with</code> block, what happens regarding the context manager's <code>__exit__</code> method?</p> <p>a. <code>__exit__</code> is skipped entirely. b. <code>__exit__</code> is called, and the exception details (type, value, traceback) are passed as arguments. c. <code>__exit__</code> is called, but all its arguments are <code>None</code>. d. The program terminates immediately before <code>__exit__</code> can be called.</p> Click to see the answer <p>The correct answer is b). The <code>__exit__</code> method is guaranteed to be called even if an exception occurs within the <code>with</code> block. The exception details are passed to it, allowing for cleanup and optional exception handling/suppression.</p>"},{"location":"module_1/chapter_1_quiz/#question-13","title":"Question 13","text":"<p>Consider the following code:</p> <pre><code>def process_value(val):\n    try:\n        print(\"Start Try\")\n        result = 100 / int(val)\n        print(\"Try Success\")\n        return result\n    except ValueError:\n        print(\"ValueError Caught\")\n        return \"Invalid Number\"\n    finally:\n        print(\"Finally Block Executed\")\n\nprint(process_value(\"5\"))\nprint(\"---\")\nprint(process_value(\"abc\"))\n</code></pre> <p>What is the exact output?</p> <p>a.</p> <pre><code>Start Try\nTry Success\nFinally Block Executed\n20.0\n---\nStart Try\nValueError Caught\nFinally Block Executed\nInvalid Number\n</code></pre> <p>b.</p> <pre><code>Start Try\nTry Success\n20.0\n---\nStart Try\nValueError Caught\nInvalid Number\n</code></pre> <p>c.</p> <pre><code>Start Try\nTry Success\nFinally Block Executed\n20.0\n---\nStart Try\nFinally Block Executed\nValueError Caught\nInvalid Number\n</code></pre> <p>d.</p> <pre><code>Start Try\nTry Success\n20.0\nFinally Block Executed\n---\nStart Try\nValueError Caught\nInvalid Number\nFinally Block Executed\n</code></pre> Click to see the answer <p>The correct answer is a). The <code>finally</code> block executes regardless of whether an exception occurred or was caught in the <code>try</code>/<code>except</code> blocks. It runs after the <code>try</code> or <code>except</code> block finishes, but before the function returns or the exception propagates (if not caught).</p>"},{"location":"module_1/chapter_1_quiz/#question-14","title":"Question 14","text":"<p>Which statement accurately describes the difference between the <code>else</code> and <code>finally</code> blocks in a <code>try...except...else...finally</code> structure?</p> <p>a. Both <code>else</code> and <code>finally</code> execute only if no exception occurs in the <code>try</code> block. b. <code>else</code> executes only if an exception occurs, while <code>finally</code> executes regardless of exceptions. c. <code>else</code> executes only if no exception occurs in the <code>try</code> block, while <code>finally</code> executes regardless of whether an exception occurred or not. d. <code>else</code> executes regardless of exceptions, while <code>finally</code> executes only if no exception occurs.</p> Click to see the answer <p>The correct answer is c). The <code>else</code> block is conditional on the <code>try</code> block completing without errors. The <code>finally</code> block provides a guarantee of execution for cleanup actions, irrespective of what happened in the <code>try</code> and <code>except</code> blocks.</p>"},{"location":"module_1/chapter_1_quiz/#question-15","title":"Question 15","text":"<p>What is the Pythonic way to get both the index and the value while iterating over a list <code>my_list</code>?</p> <p>a.</p> <pre><code>index = 0\nfor value in my_list:\n    print(f\"Index {index}: {value}\")\n    index += 1\n</code></pre> <p>b.</p> <pre><code>for index in range(len(my_list)):\n    value = my_list[index]\n    print(f\"Index {index}: {value}\")\n</code></pre> <p>c.</p> <pre><code>for index, value in enumerate(my_list):\n    print(f\"Index {index}: {value}\")\n</code></pre> <p>d.</p> <pre><code>for value in my_list:\n    index = my_list.index(value)\n    print(f\"Index {index}: {value}\")\n</code></pre> Click to see the answer <p>The correct answer is c). The built-in <code>enumerate()</code> function is the standard and most Pythonic way to iterate over both the index and value of a sequence simultaneously.</p>"},{"location":"module_1/chapter_1_quiz/#question-16","title":"Question 16","text":"<p>Consider <code>list1 = ['a', 'b']</code> and <code>list2 = [1, 2, 3]</code>. What will <code>list(zip(list1, list2))</code> produce?</p> <p>a. <code>[('a', 1), ('b', 2), (None, 3)]</code> b. <code>[('a', 1), ('b', 2)]</code> c. <code>[('a', 'b'), (1, 2, 3)]</code> d. An error because the lists have different lengths.</p> Click to see the answer <p>The correct answer is b). <code>zip</code> pairs elements from iterables until the shortest iterable is exhausted. It stops after pairing 'b' with 2.</p>"},{"location":"module_1/chapter_1_quiz/#question-17","title":"Question 17","text":"<p>Which naming style does PEP 8 recommend for Python class names?</p> <p>a. <code>snake_case</code> (e.g., <code>my_class</code>) b. <code>camelCase</code> (e.g., <code>myClass</code>) c. <code>UPPER_SNAKE_CASE</code> (e.g., <code>MY_CLASS</code>) d. <code>CapitalizedWords</code> (also known as CapWords or PascalCase) (e.g., <code>MyClass</code>)</p> Click to see the answer <p>The correct answer is d). PEP 8 specifically recommends using the <code>CapitalizedWords</code> convention for class names.</p>"},{"location":"module_1/chapter_1_quiz/#question-18","title":"Question 18","text":"<p>Given the following multiple inheritance structure (a \"diamond pattern\"):</p> <pre><code>class A:\n    def ping(self):\n        print(\"Ping from A\")\n\nclass B(A):\n    def ping(self):\n        print(\"Ping from B\")\n        super().ping()\n\nclass C(A):\n    def ping(self):\n        print(\"Ping from C\")\n        super().ping()\n\nclass D(B, C): # Note the order: B, then C\n    def ping(self):\n        print(\"Ping from D\")\n        super().ping()\n\nd = D()\nd.ping()\n</code></pre> <p>What will be the exact output of <code>d.ping()</code>?</p> <p>a.</p> <pre><code>Ping from D\nPing from B\nPing from A\n</code></pre> <p>b.</p> <pre><code>Ping from D\nPing from C\nPing from A\n</code></pre> <p>c.</p> <pre><code>Ping from D\nPing from B\nPing from C\nPing from A\n</code></pre> <p>d.</p> <pre><code>Ping from D\nPing from B\nPing from C\nPing from A\nPing from A\n</code></pre> Click to see the answer <pre><code>The correct answer is **c)**. Python uses the C3 linearization algorithm to determine the Method Resolution Order (MRO). For class D(B, C), the MRO is `(D, B, C, A, object)`. When `super().ping()` is called:\n1. In `D`, `super()` refers to `B`. Output: `Ping from D`. Call `B.ping()`.\n2. In `B`, `super()` refers to `C` (the *next* class in D's MRO after B). Output: `Ping from B`. Call `C.ping()`.\n3. In `C`, `super()` refers to `A` (the *next* class in D's MRO after C). Output: `Ping from C`. Call `A.ping()`.\n4. In `A`, `ping()` executes. Output: `Ping from A`. `super()` would refer to `object`, which doesn't have `ping`.\nThe final output follows the MRO: D -&gt; B -&gt; C -&gt; A.\n</code></pre>"},{"location":"module_1/chapter_1_quiz/#question-19","title":"Question 19","text":"<p>Which of the following variable names violates typical PEP 8 naming conventions for regular variables or functions?</p> <p>a. <code>user_id</code> b. <code>MAX_CONNECTIONS</code> c. <code>calculateTotalAmount</code> d. <code>_internal_helper</code></p> Click to see the answer <p>The correct answer is c). PEP 8 recommends <code>snake_case</code> (lowercase with underscores) for function and variable names (<code>calculate_total_amount</code>). <code>UPPER_SNAKE_CASE</code> is for constants, <code>_leading_underscore</code> indicates internal use, and <code>camelCase</code> (like <code>calculateTotalAmount</code>) is generally discouraged for variables/functions in Python, though common in other languages.</p>"},{"location":"module_1/chapter_1_quiz/#question-20","title":"Question 20","text":"<p>Consider the function definition: <code>def process_items(id, *items, status=\"pending\", **details):</code>. Which of the following function calls is invalid?</p> <p>a. <code>process_items(101, 'apple', 'banana', status=\"done\", user=\"admin\")</code> b. <code>process_items(102, 'item1', 'item2', priority=3)</code> c. <code>process_items(103, status=\"failed\", error_code=5, 'item3')</code> d. <code>process_items(104)</code></p> Click to see the answer <p>The correct answer is c). Positional arguments (<code>'item3'</code>) cannot follow keyword arguments (<code>status=\"failed\", error_code=5</code>). Once keyword arguments are used in a call, all subsequent arguments must also be keyword arguments. <code>*items</code> collects positional arguments after <code>id</code>, and <code>**details</code> collects any keyword arguments not explicitly named (<code>status</code> in this case).</p>"},{"location":"module_1/chapter_2/","title":"Chapter 2: Environment, Dependencies &amp; Build Tools","text":"<p>Estimated Time: 5 hours</p> <p>Goal: To equip developers with the knowledge and skills to effectively manage project environments, dependencies, package structure, and build processes, ensuring project reproducibility and maintainability.</p>"},{"location":"module_1/chapter_2/#21-virtual-environments","title":"2.1 Virtual Environments","text":"<ul> <li>Objective: Understand the importance of isolated environments and how to create them using <code>venv</code> (Python).</li> <li>Topics:</li> <li>Why Isolation? Prevent library conflicts between projects.</li> <li>What is venv? A tool to create isolated Python environments.</li> <li>Creating venv: <code>python3 -m venv .venv</code> makes a new environment.</li> <li>Using venv: Activate to use its Python/libraries, deactivate to switch back.</li> <li>Benefits: Keep projects organized, avoid clashes, ensure reproducibility.</li> <li> <p>Example Snippet (Creating and Using a Virtual Environment):</p> <pre><code># --- Example: Creating and Using a Virtual Environment ---\n\n# Create a virtual environment named \".venv\" in the current directory\npython3 -m venv .venv\n\n# Activate the virtual environment (Linux/macOS)\nsource .venv/bin/activate\n\n# (venv) should now appear in your shell prompt\n\n# Install a package within the virtual environment\npip install requests\n\n# Use the installed package\npython -c \"import requests; print(requests.get('[https://www.example.com](https://www.example.com)'))\"\n\n# Deactivate the virtual environment\ndeactivate\n\n# The (venv) part of the prompt should disappear\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_2/#22-dependency-management-pip","title":"2.2 Dependency Management (pip)","text":"<ul> <li>Objective: Learn how to manage project dependencies using <code>pip</code>.</li> <li>Topics:</li> <li><code>pip</code> as Python's package installer.</li> <li>Installing packages (<code>pip install &lt;package_name&gt;</code>).</li> <li>Specifying versions (<code>pip install &lt;package_name&gt;==&lt;version&gt;</code>, <code>pip install &lt;package_name&gt;&gt;=&lt;min_version&gt;</code>, etc.).</li> <li>Upgrading packages (<code>pip install --upgrade &lt;package_name&gt;</code>).</li> <li>Uninstalling packages (<code>pip uninstall &lt;package_name&gt;</code>).</li> <li>Listing installed packages (<code>pip list</code>, <code>pip show &lt;package_name&gt;</code>).</li> <li>Generating <code>requirements.txt</code> (<code>pip freeze &gt; requirements.txt</code>).</li> <li>(Old simple way) Installing from <code>requirements.txt</code> (<code>pip install -r requirements.txt</code>).</li> <li>Modern project setup with <code>pyproject.toml</code>.</li> <li> <p>Example Snippet (Using <code>pip</code>):</p> <pre><code># --- Example: Managing Dependencies with pip ---\n\n# Install a specific version of Flask\npip install Flask==2.1.2\n\n# Upgrade Flask\npip install --upgrade Flask\n\n# Create a requirements.txt file\npip freeze &gt; requirements.txt\n\n# Install dependencies from requirements.txt\npip install -r requirements.txt\n\n# Show information about the installed Flask package\npip show Flask\n</code></pre> </li> <li> <p>Example Snippet (<code>pyproject.toml</code>):</p> <pre><code># --- Example: pyproject.toml ---\n\n[project]\nname = \"my_project\"\nversion = \"0.1.0\"\ndependencies = [\n    \"requests &gt;= 2.28.0\",\n    \"flask == 2.2.3\"\n]\n\n[build-system]\n# Specifies the tools required to build the project\nrequires = [\"setuptools&gt;=61.0.0\"]\nbuild-backend = \"setuptools.build_meta\"\n</code></pre> <pre><code># To install dependencies from pyproject.toml (using pip)\n# You still typically use pip, but it leverages the build system info:\npip install .  # Installs the current project and its dependencies\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_2/#23-package-structure","title":"2.3 Package Structure","text":"<ul> <li>Objective: Learn how to structure Python projects for organization and maintainability.</li> <li>Topics:</li> <li>Basic project layout:<ul> <li><code>src/</code>: Where the main application code resides</li> <li><code>tests/</code>: For test code</li> <li><code>README.md</code>: Project documentation</li> <li><code>requirements.txt</code>: Legacy way to list dependencies</li> <li><code>pyproject.toml</code>: Modern file for project metadata and build configuration.</li> </ul> </li> <li>Packages vs. Modules: A Python module is a single <code>.py</code> file; a package is a directory containing module files and an <code>__init__.py</code> file.</li> <li><code>__init__.py</code> files (for Python &lt; 3.3, and for defining package-level imports).</li> <li>Importing Code: Prefer absolute imports for clarity; use relative imports within packages.</li> <li> <p>Example Snippet (Basic Project Structure):</p> <pre><code># --- Example: Basic Project Structure ---\nmy_project/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 my_package/\n\u2502   \u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u2502   \u251c\u2500\u2500 module1.py\n\u2502   \u2502   \u2514\u2500\u2500 module2.py\n\u2502   \u2514\u2500\u2500 main.py\n\u251c\u2500\u2500 tests/\n\u2502   \u2514\u2500\u2500 test_module1.py\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 requirements.txt\n</code></pre> <pre><code># --- Example: Absolute vs. Relative Imports ---\n# src/my_package/module2.py\nfrom my_package import module1  # Absolute import (from top-level package)\nfrom . import module1          # Relative import (from same package)\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_2/#24-build-processes","title":"2.4 Build Processes","text":"<ul> <li>Objective: Introduce the concepts of building and packaging Python projects.</li> <li>Topics:</li> <li>Why Build and Package?: To prepare your project for distribution and installation.</li> <li><code>setuptools</code> for building distributions (handled by <code>pyproject.toml</code> in modern projects).</li> <li><code>pyproject.toml</code> for package metadata and build configuration.</li> <li>Building source distributions (<code>sdist</code>): Packages your project's source code, metadata, and installation details into a distributable archive, facilitating installation and handling extension module compilation.</li> <li>Building wheels (<code>wheel</code>): Creates a pre-built distribution that installs faster and is generally preferred over source distributions.</li> <li><code>twine</code>: A tool to upload your packages to PyPI.</li> <li> <p>Example Snippet (<code>pyproject.toml</code>):</p> <pre><code># --- Example: pyproject.toml ---\n[project]\nname = \"my_package\"\nversion = \"0.1.0\"\nauthors = [\n    { name = \"Your Name\", email = \"your.email@example.com\" }\n]\ndescription = \"A sample package\"\nreadme = \"README.md\"\nrequires-python = \"&gt;=3.8\"\nclassifiers = [\n    \"Programming Language :: Python :: 3 :: Only\",\n    \"License :: OSI Approved :: MIT License\",\n    \"Operating System :: OS Independent\",\n]\ndependencies = [\n    \"requests &gt;= 2.28.0\",\n    \"flask == 2.2.3\"\n]\n\n[project.optional-dependencies]\ndev = [\n    \"pytest&gt;=7.0\",\n    \"coverage\"\n]\n\n[project.scripts]\nmy-script = \"my_package.main:cli\"  # If you have a CLI entry point\n\n[build-system]\n# Specifies the tools required to build the project\nrequires = [\"setuptools&gt;=61.0.0\", \"wheel\"]\nbuild-backend = \"setuptools.build_meta\"\n</code></pre> <pre><code># --- Example: Building and Installing with pyproject.toml ---\n# Assuming you have a pyproject.toml configured for setuptools\npython -m build  # Uses the 'build' package to build from pyproject.toml\n# This creates a 'dist' directory with sdist and wheel files\n\n# To install the wheel (from the 'dist' directory)\npip install dist/my_package-0.1.0-py3-none-any.whl\n# Or install the sdist\npip install dist/my_package-0.1.0.tar.gz\n\n# To install the package in \"editable\" mode (for development)\npip install -e .\n\n# To publish the package to PyPI (requires twine)\n# twine upload dist/*\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_3/","title":"Chapter 3: Testing Strategies","text":"<p>Estimated Time: 8 hours</p> <p>Goal: To equip developers with a comprehensive understanding of software testing principles and practices, including unit testing, mocking, TDD, and basic integration testing.</p>"},{"location":"module_1/chapter_3/#31-unit-testing-with-pytest","title":"3.1 Unit Testing with <code>pytest</code>","text":"<ul> <li> <p>Objective: Learn how to write effective unit tests using the <code>pytest</code> framework.</p> </li> <li> <p>Topics:</p> </li> <li> <p><code>pytest</code> framework:</p> <ul> <li>Test Discovery: pytest automatically collects test cases by identifying files (e.g., <code>test_*.py</code> or <code>*_test.py</code>) and functions (e.g., <code>test_*</code> or <code>*_test</code>).</li> <li>Use <code>assert</code> to verify conditions in your code.</li> <li>Test Organization: Structure your test code using functions (for simple tests) or classes (for grouping related tests and setup/teardown) to improve clarity.</li> <li>Test Fixtures: Manage test setup and teardown.</li> <li>Test Parametrization: Run tests with multiple inputs.</li> <li>Test Marking: Tag tests with markers (using decorators like <code>@pytest.mark.marker_name</code>) to skip them, mark them as expected to fail, or group them for selective execution.</li> <li>pytest Configuration: Configure pytest settings (e.g., test discovery, markers) using the <code>pytest.ini</code> file.</li> </ul> </li> <li> <p>Writing good unit tests:</p> <ul> <li>AAA Pattern: Structure tests as Arrange-Act-Assert.</li> <li>Testing Edge Cases: Test with unusual inputs.</li> <li>Test Best Practices: Adhere to principles of independence (avoid shared state, use proper setup/teardown), speed (fast execution for rapid feedback), and focus (test one unit/behavior) to create reliable and maintainable tests.</li> </ul> </li> <li> <p>Example Snippet (Basic <code>pytest</code>):</p> <pre><code>#   --- Example: Basic pytest ---\n#   test_calculator.py\ndef   add(x, y):\n    return   x + y\n\ndef   test_add_positive_numbers():\n    assert   add(2, 3) == 5\n\ndef   test_add_negative_numbers():\n    assert   add(-1, -1) == -2\n\ndef   test_add_mixed_numbers():\n    assert   add(5, -2) == 3\n</code></pre> <pre><code>#   Running the tests\npytest test_calculator.py\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_3/#32-mocking","title":"3.2 Mocking","text":"<ul> <li> <p>Objective: Understand the concept of mocking and how to use mocking libraries to isolate units under test.</p> </li> <li> <p>Topics:</p> </li> <li> <p>Stubs vs. Mocks vs. Spies:</p> <ul> <li>Stubs: Provide fixed return values or responses to calls, primarily used to control the state of dependencies.</li> <li>Mocks: More advanced than stubs; they also allow you to verify that specific interactions with the substitute occurred (e.g., that a method was called with certain arguments).</li> <li>Spies: A type of mock that also records how the substitute was used, allowing you to both control its behavior and assert on its interactions.</li> </ul> </li> <li> <p><code>unittest.mock</code> (Python's built-in mocking library):</p> <ul> <li><code>Mock</code> class: (Used to create basic mock objects to stand in for real classes or instances).</li> <li><code>MagicMock</code> class: (Extends <code>Mock</code> to easily handle method calls and magic methods).</li> <li><code>patch()</code> decorator/context manager: (Simplifies the process of replacing objects with mocks during tests).</li> <li>Asserting calls and interactions: (Use methods like <code>assert_called_once_with()</code> and <code>assert_called()</code> to verify how mock objects were called during the test).</li> </ul> </li> <li> <p>Example Snippet (<code>unittest.mock</code>): #TODO Review this example and provide another one more explanatory or real</p> <pre><code>#   --- Example: unittest.mock ---\nimport unittest\nfrom unittest.mock import Mock, MagicMock, patch\n\nclass ProductionClass:\n    def method_that_calls_external(self):\n        return ExternalDependency.get_data()  # Relies on an external component\n\nclass ExternalDependency:\n    @staticmethod\n    def get_data():\n        # In a real system, this might hit a database or API\n        raise NotImplementedError(\"This is a real external call\")\n\n\nclass TestProductionClass(unittest.TestCase):\n\n    def test_method_calls_external_with_mock(self):\n        # 1. Mocking a function directly (using Mock)\n        ExternalDependency.get_data = Mock(return_value=\"Mocked Data\")\n        instance = ProductionClass()\n        result = instance.method_that_calls_external()\n        self.assertEqual(result, \"Mocked Data\")\n        ExternalDependency.get_data.assert_called_once()  # Verify it was called\n\n    def test_method_calls_external_with_patch(self):\n        # 2. Mocking with patch (as a decorator)\n        @patch('__main__.ExternalDependency.get_data')  # Target the full path\n        def test_using_patch(mock_get_data):\n            mock_get_data.return_value = \"Patched Data\"\n            instance = ProductionClass()\n            result = instance.method_that_calls_external()\n            self.assertEqual(result, \"Patched Data\")\n            mock_get_data.assert_called_once()\n\n        test_using_patch()  # Execute the patched test\n\n    def test_method_calls_external_with_magicmock(self):\n        # 3. Mocking with MagicMock (for methods/magic methods)\n        mock_external = MagicMock()\n        mock_external.get_data.return_value = \"Magic Mocked\"\n        with patch('__main__.ExternalDependency', new=mock_external):\n            instance = ProductionClass()\n            result = instance.method_that_calls_external()\n            self.assertEqual(result, \"Magic Mocked\")\n            mock_external.get_data.assert_called_once()\n\n\n    def test_method_calls_external_with_spy_like_behavior(self):\n        # 4. Demonstrating \"spy\" like behavior with call_args_list\n\n        # Let's say we want to track all calls to a method\n        with patch('__main__.ExternalDependency.get_data') as mock_get_data:\n            instance = ProductionClass()\n            instance.method_that_calls_external()\n            instance.method_that_calls_external()\n            instance.method_that_calls_external(10)  # Call with an argument\n            instance.method_that_calls_external(\"abc\")\n\n            # Inspecting calls\n            self.assertEqual(mock_get_data.call_count, 4)  # Total calls\n            self.assertEqual(mock_get_data.call_args_list[0], unittest.mock.call()) # First call\n            self.assertEqual(mock_get_data.call_args_list[2], unittest.mock.call(10)) # Call with arg\n            self.assertEqual(mock_get_data.call_args_list[3], unittest.mock.call(\"abc\"))\n</code></pre> </li> </ul>"},{"location":"module_1/chapter_4-2/","title":"Chapter 4 2","text":""},{"location":"module_1/chapter_4-2/#module-1-advanced-python-best-practices","title":"Module 1: Advanced Python &amp; Best Practices","text":""},{"location":"module_1/chapter_4-2/#chapter-4-project-refactoring-enhancing-an-existing-python-application","title":"Chapter 4: Project - Refactoring &amp; Enhancing an Existing Python Application","text":"<p>Estimated Time: 20 hours</p> <p>Goal: To practically apply Python best practices, refactoring techniques, testing strategies, and feature enhancement to an existing codebase. This chapter uses the \"Data Processor\" project defined in <code>dev_course_module1_project_v1</code>.</p> <p>Project Overview (Recap from <code>dev_course_module1_project_v1</code>):</p> <p>You will start with the <code>data_processor_v0.py</code> script. This script reads employee data from a CSV, calculates total salary, and finds the highest earner. Your main objectives are to:</p> <ol> <li> <p>Refactor the existing code for clarity, efficiency, and Pythonic style.</p> </li> <li> <p>Extend its functionality with new features (average salary per department) and robustness (error handling, logging).</p> </li> <li> <p>Write unit tests for the core logic.</p> </li> </ol> <p>4.1: Project Setup: Understanding the Provided Codebase, Setting up Environment</p> <ul> <li> <p>Objective: Familiarize yourself with the initial project code and set up your development environment.</p> </li> <li> <p>Tasks:</p> <ol> <li> <p>Retrieve the Initial Code (<code>data_processor_v0.py</code>) and the sample <code>employees.csv</code> file.</p> </li> <li> <p>Create a dedicated Project Directory.</p> </li> <li> <p>Set up and activate a Virtual Environment for the project.</p> </li> <li> <p>Run the <code>data_processor_v0.py</code> script with the sample CSV to observe its current behavior and output.</p> </li> <li> <p>Thoroughly review <code>data_processor_v0.py</code> to understand its current functionality, data flow, and structure.</p> </li> </ol> </li> </ul> <p>4.2: Code Analysis and Refactoring Strategy</p> <ul> <li> <p>Objective: Analyze <code>data_processor_v0.py</code> to identify areas for improvement based on Chapter 1 concepts and devise a refactoring strategy.</p> </li> <li> <p>Tasks:</p> <ol> <li> <p>Evaluate the script's current file handling mechanism. How can it be made more robust, especially concerning resource cleanup in case of errors?</p> </li> <li> <p>Assess the current data structure used for employee records. Is it optimal for clarity and ease of access? Consider alternatives.</p> </li> <li> <p>Analyze the script's iteration and data processing logic. Are there opportunities for improved efficiency or more Pythonic approaches?</p> </li> <li> <p>Identify any \"magic numbers\" or hardcoded indices used for data access. How can these be improved for better readability and maintainability?</p> </li> <li> <p>Review the script's error handling. Is it specific enough? How are different types of errors (e.g., file not found, data conversion errors, missing data) currently managed, and how could this be improved?</p> </li> <li> <p>Examine the code for adherence to PEP 8 style guidelines and overall Pythonic style.</p> </li> <li> <p>Consider if the main processing function has too many responsibilities. Could it benefit from decomposition into smaller, more focused functions or by introducing classes?</p> </li> </ol> </li> </ul> <p>4.3: Implementing Core Refactoring</p> <ul> <li> <p>Objective: Implement foundational refactoring changes to improve the codebase's structure, readability, and resource management.</p> </li> <li> <p>Tasks:</p> <ol> <li> <p>Refactor the file I/O to use a context manager, ensuring files are properly closed.</p> </li> <li> <p>Implement a more structured data representation for individual employee records (e.g., using dictionaries, namedtuples, or a custom class).</p> </li> <li> <p>Modify the data reading and processing logic to operate more directly on the data stream (e.g., process rows as they are read from the CSV reader) and use the new structured data representation.</p> </li> <li> <p>Replace indexed access to data fields with named access based on your chosen data structure.</p> </li> </ol> </li> </ul> <p>4.4: Enhancing Functionality and Robustness</p> <ul> <li> <p>Objective: Extend the script with new features and make it more robust.</p> </li> <li> <p>Tasks:</p> <ol> <li> <p>Implement functionality to calculate the average salary for each department. This will require grouping or aggregating data by department.</p> </li> <li> <p>Incorporate specific error handling for various potential issues, such as:</p> <ul> <li> <p><code>FileNotFoundError</code> if the input CSV is not found.</p> </li> <li> <p>Errors during data conversion (e.g., non-numeric salary).</p> </li> <li> <p>Rows with an incorrect number of columns or missing essential data.</p> </li> <li> <p>Empty files or files containing only a header row.</p> </li> <li> <p>Potential division by zero when calculating averages if a department has no valid salary entries.</p> </li> </ul> </li> <li> <p>Integrate the <code>logging</code> module to record key events, such as the start and end of processing, files being processed, errors encountered, and rows skipped due to issues. Define a clear logging format and appropriate log levels.</p> </li> <li> <p>Define a custom exception class (e.g., <code>DataProcessingError</code>) for application-specific errors that are not covered by built-in exceptions.</p> </li> </ol> </li> </ul> <p>4.5: Writing Unit Tests</p> <ul> <li> <p>Objective: Develop a suite of unit tests to ensure the correctness of the refactored and extended data processing logic.</p> </li> <li> <p>Tasks:</p> <ol> <li> <p>Set up a testing environment using <code>unittest</code> or <code>pytest</code>. Create a <code>tests</code> directory and test files.</p> </li> <li> <p>Write unit tests for the original core functionalities:</p> <ul> <li> <p>Total salary calculation.</p> </li> <li> <p>Identification of the highest earner.</p> </li> </ul> </li> <li> <p>Write unit tests for the new functionality:</p> <ul> <li>Average salary per department calculation.</li> </ul> </li> <li> <p>Develop strategies for testing logic that involves file I/O. This might involve mocking <code>open</code> and <code>csv.reader</code> or refactoring parts of your code to accept iterable data directly.</p> </li> <li> <p>Create tests for various edge cases and error conditions, including:</p> <ul> <li> <p>Processing an empty CSV file.</p> </li> <li> <p>Processing a CSV file with only a header row.</p> </li> <li> <p>Processing CSV files containing rows with invalid data (e.g., non-numeric salary, missing columns).</p> </li> <li> <p>File not found scenarios.</p> </li> </ul> </li> <li> <p>Ensure your tests cover different valid data scenarios to verify the accuracy of calculations.</p> </li> </ol> </li> </ul> <p>4.6: Code Polishing and Finalization</p> <ul> <li> <p>Objective: Ensure the final codebase is clean, well-documented, and adheres to Python best practices.</p> </li> <li> <p>Tasks:</p> <ol> <li> <p>Perform a thorough PEP 8 compliance check using a linter (e.g., <code>flake8</code>).</p> </li> <li> <p>Use an auto-formatter (e.g., <code>black</code>) to ensure consistent code style.</p> </li> <li> <p>Review and ensure all functions, classes, and modules have clear and comprehensive docstrings.</p> </li> <li> <p>Add inline comments to explain any complex or non-obvious sections of code.</p> </li> <li> <p>Create a <code>requirements.txt</code> file listing any external dependencies (e.g., <code>pytest</code>, <code>pytest-mock</code> if used).</p> </li> </ol> </li> </ul>"},{"location":"module_1/chapter_4/","title":"Chapter 4","text":""},{"location":"module_1/chapter_4/#chapter-4-project-solution-refactored-data-processor","title":"Chapter 4 Project Solution: Refactored Data Processor","text":"<p>This document provides a potential solution to the Chapter 4 project, demonstrating refactoring, feature extension, and unit testing based on the concepts covered in Chapter 1.</p> <p>1. Refactored and Extended Code (<code>data_processor_refactored.py</code>)</p> <p>This version incorporates:</p> <ul> <li> <p>Context managers for file handling.</p> </li> <li> <p>OOP using an <code>Employee</code> class (or <code>namedtuple</code> could also be used).</p> </li> <li> <p>Direct iteration over the CSV reader.</p> </li> <li> <p>Specific error handling (<code>try...except</code>).</p> </li> <li> <p>Logging using the <code>logging</code> module.</p> </li> <li> <p>Calculation of average salary per department.</p> </li> <li> <p>PEP 8 styling and clearer naming.</p> </li> </ul> <pre><code># --- Refactored Code ---\n# (Save this as data_processor_refactored.py)\n\nimport csv\nimport logging\nfrom collections import defaultdict, namedtuple\n\n# Configure basic logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n\n# Using namedtuple for simple data structure\n# Alternatively, a full class could be defined with methods if more complexity was needed\nEmployee = namedtuple(\"Employee\", [\"id\", \"name\", \"department\", \"salary\"])\n\nclass DataProcessingError(Exception):\n    \"\"\"Custom exception for data processing issues.\"\"\"\n    pass\n\ndef parse_employee(row: list, row_num: int) -&gt; Employee | None:\n    \"\"\"\n    Parses a single row from the CSV into an Employee object.\n    Handles potential conversion errors for a single row.\n    Returns None if parsing fails.\n    \"\"\"\n    try:\n        # Check for expected number of columns\n        if len(row) != 4:\n            raise ValueError(f\"Incorrect number of columns ({len(row)} instead of 4)\")\n\n        emp_id = int(row[0])\n        name = row[1].strip()\n        department = row[2].strip()\n        salary = float(row[3])\n\n        if not name or not department:\n             raise ValueError(\"Missing name or department\")\n        if salary &lt; 0:\n             raise ValueError(\"Negative salary\")\n\n        return Employee(id=emp_id, name=name, department=department, salary=salary)\n\n    except ValueError as e:\n        logging.warning(f\"Skipping row {row_num}: Invalid data format in row {row}. Error: {e}\")\n        return None\n    except IndexError:\n        logging.warning(f\"Skipping row {row_num}: Missing columns in row {row}.\")\n        return None\n\ndef process_employee_data(filepath: str) -&gt; dict:\n    \"\"\"\n    Reads employee data from a CSV file, calculates aggregate statistics,\n    and handles potential errors during processing.\n\n    Args:\n        filepath: The path to the employee CSV file.\n\n    Returns:\n        A dictionary containing processing results:\n        {\n            'total_salary': float,\n            'highest_earner': Employee | None,\n            'average_salary_per_department': dict[str, float],\n            'processed_rows': int,\n            'skipped_rows': int\n        }\n\n    Raises:\n        FileNotFoundError: If the specified filepath does not exist.\n        DataProcessingError: If the file is empty or contains only headers.\n    \"\"\"\n    logging.info(f\"Starting processing for file: {filepath}\")\n\n    total_salary = 0.0\n    highest_salary = -1.0\n    highest_earner = None\n    department_stats = defaultdict(lambda: {\"total_salary\": 0.0, \"count\": 0})\n    processed_rows = 0\n    skipped_rows = 0\n\n    try:\n        # Use context manager for safe file handling\n        with open(filepath, mode='r', newline='', encoding='utf-8') as file:\n            reader = csv.reader(file)\n\n            try:\n                # Read header safely\n                header = next(reader)\n                logging.info(f\"CSV Header: {header}\")\n                processed_rows += 1 # Count header row conceptually\n            except StopIteration:\n                raise DataProcessingError(\"File is empty.\")\n\n            # Iterate directly over reader using enumerate for row numbers (starting after header)\n            for i, row in enumerate(reader, start=2): # Start row count from 2 for logging\n                employee = parse_employee(row, i)\n\n                if employee:\n                    total_salary += employee.salary\n                    department_stats[employee.department][\"total_salary\"] += employee.salary\n                    department_stats[employee.department][\"count\"] += 1\n\n                    if employee.salary &gt; highest_salary:\n                        highest_salary = employee.salary\n                        highest_earner = employee\n                    processed_rows += 1\n                else:\n                    skipped_rows += 1\n\n    except FileNotFoundError:\n        logging.error(f\"Error: File not found at {filepath}\")\n        raise # Re-raise the exception after logging\n    except Exception as e: # Catch other potential I/O errors\n        logging.error(f\"An unexpected error occurred during file processing: {e}\")\n        raise DataProcessingError(f\"Failed to process file due to: {e}\") from e\n\n    if processed_rows &lt;= 1 and skipped_rows == 0: # Only header was processed\n         raise DataProcessingError(\"File contains only headers or is effectively empty.\")\n\n    # Calculate averages\n    average_salary_per_department = {}\n    for dept, stats in department_stats.items():\n        if stats[\"count\"] &gt; 0:\n            average_salary_per_department[dept] = round(stats[\"total_salary\"] / stats[\"count\"], 2)\n        else:\n             average_salary_per_department[dept] = 0.0 # Or handle as appropriate\n\n    logging.info(f\"Processing Complete. Processed data rows: {processed_rows-1}, Skipped rows: {skipped_rows}\") # -1 for header\n\n    results = {\n        'total_salary': round(total_salary, 2),\n        'highest_earner': highest_earner,\n        'average_salary_per_department': average_salary_per_department,\n        'processed_rows': processed_rows -1, # Exclude header\n        'skipped_rows': skipped_rows\n    }\n\n    return results\n\n# Example Usage (requires 'employees.csv')\nif __name__ == \"__main__\":\n    try:\n        results = process_employee_data('employees.csv')\n        print(\"\\n--- Processing Results ---\")\n        print(f\"Total Salary Expenditure: ${results['total_salary']:.2f}\")\n        if results['highest_earner']:\n            print(f\"Highest Earner: {results['highest_earner'].name} with ${results['highest_earner'].salary:.2f}\")\n        else:\n            print(\"Highest Earner: Not found (no valid data).\")\n        print(\"Average Salary Per Department:\")\n        for dept, avg_salary in results['average_salary_per_department'].items():\n            print(f\"  - {dept}: ${avg_salary:.2f}\")\n        print(f\"Processed Rows (data): {results['processed_rows']}\")\n        print(f\"Skipped Rows: {results['skipped_rows']}\")\n    except (FileNotFoundError, DataProcessingError) as e:\n        print(f\"\\nProcessing failed: {e}\")\n    except Exception as e:\n        print(f\"\\nAn unexpected error occurred: {e}\")\n</code></pre> <p>2. Unit Tests (<code>test_data_processor.py</code>)</p> <p>This example uses <code>pytest</code> and <code>unittest.mock</code>. You would need to install them (<code>pip install pytest pytest-mock</code>).</p> <pre><code># --- Unit Tests ---\n# (Save this as test_data_processor.py in a 'tests' subdirectory)\n\nimport pytest\nfrom unittest.mock import mock_open, patch\nimport csv\nimport io  # Used for mocking file content\n\n# Import the refactored function and Employee namedtuple\n# Assuming the refactored file is in the parent directory or accessible via PYTHONPATH\n# Adjust the import path as necessary for your project structure\nfrom data_processor_refactored import process_employee_data, Employee, DataProcessingError\n\n# --- Test Data ---\nVALID_CSV_DATA = \"\"\"ID,Name,Department,Salary\n1,Alice,Engineering,90000\n2,Bob,Sales,80000\n3,Charlie,Engineering,95000\n4,David,HR,70000\n5,Eve,Sales,82000\n\"\"\"\n\nEDGE_CASE_CSV_DATA_INVALID_SALARY = \"\"\"ID,Name,Department,Salary\n1,Alice,Engineering,90000\n2,Bob,Sales,Eighty Thousand\n3,Charlie,Engineering,95000\n\"\"\"\n\nEDGE_CASE_CSV_DATA_MISSING_COLUMN = \"\"\"ID,Name,Department,Salary\n1,Alice,Engineering,90000\n2,Bob,Sales\n3,Charlie,Engineering,95000\n\"\"\"\n\nEMPTY_CSV_DATA = \"\"\nHEADER_ONLY_CSV_DATA = \"ID,Name,Department,Salary\\n\"\n\n# --- Test Fixtures (Optional but good practice with pytest) ---\n@pytest.fixture\ndef mock_csv_file():\n    \"\"\"Fixture to mock the open() call and csv.reader.\"\"\"\n    def _mock_file(content):\n        # Use io.StringIO to simulate a file object from a string\n        mock_file_obj = io.StringIO(content)\n        # Patch 'open' in the context of the module being tested\n        m_open = mock_open(read_data=content)\n        # We need to make the mock file object behave like an iterator for csv.reader\n        m_open.return_value.__iter__ = lambda self: iter(self.readline, '')\n        m_open.return_value.__next__ = lambda self: next(iter(self.readline, ''))\n        return m_open\n    return _mock_file\n\n# --- Test Cases ---\n\ndef test_process_valid_data(mock_csv_file):\n    \"\"\"Tests processing with a standard valid CSV.\"\"\"\n    mock_opener = mock_csv_file(VALID_CSV_DATA)\n    with patch('builtins.open', mock_opener):\n        results = process_employee_data('dummy_path.csv')\n\n        assert results['total_salary'] == 417000.00\n        assert results['highest_earner'] == Employee(id=3, name='Charlie', department='Engineering', salary=95000.0)\n        assert results['average_salary_per_department'] == {\n            'Engineering': 92500.00,\n            'Sales': 81000.00,\n            'HR': 70000.00\n        }\n        assert results['processed_rows'] == 5\n        assert results['skipped_rows'] == 0\n\ndef test_process_invalid_salary(mock_csv_file):\n    \"\"\"Tests handling of rows with non-numeric salary.\"\"\"\n    mock_opener = mock_csv_file(EDGE_CASE_CSV_DATA_INVALID_SALARY)\n    with patch('builtins.open', mock_opener):\n        results = process_employee_data('dummy_path.csv')\n\n        assert results['total_salary'] == 185000.00 # Only Alice and Charlie\n        assert results['highest_earner'] == Employee(id=3, name='Charlie', department='Engineering', salary=95000.0)\n        assert results['average_salary_per_department'] == {\n            'Engineering': 92500.00 # Average of Alice and Charlie\n            # Sales department has no valid entries\n        }\n        assert results['processed_rows'] == 2\n        assert results['skipped_rows'] == 1 # Bob's row skipped\n\ndef test_process_missing_column(mock_csv_file):\n    \"\"\"Tests handling of rows with missing columns.\"\"\"\n    mock_opener = mock_csv_file(EDGE_CASE_CSV_DATA_MISSING_COLUMN)\n    with patch('builtins.open', mock_opener):\n        results = process_employee_data('dummy_path.csv')\n\n        assert results['total_salary'] == 185000.00 # Alice and Charlie\n        assert results['highest_earner'] == Employee(id=3, name='Charlie', department='Engineering', salary=95000.0)\n        assert results['average_salary_per_department'] == {\n            'Engineering': 92500.00\n        }\n        assert results['processed_rows'] == 2\n        assert results['skipped_rows'] == 1 # Bob's row skipped\n\ndef test_file_not_found():\n    \"\"\"Tests FileNotFoundError handling.\"\"\"\n    # No need to mock open here, we want the actual error\n    with pytest.raises(FileNotFoundError):\n        process_employee_data('non_existent_file.csv')\n\ndef test_empty_file(mock_csv_file):\n    \"\"\"Tests processing an empty file.\"\"\"\n    mock_opener = mock_csv_file(EMPTY_CSV_DATA)\n    with patch('builtins.open', mock_opener):\n        with pytest.raises(DataProcessingError, match=\"File is empty\"):\n            process_employee_data('dummy_path.csv')\n\ndef test_header_only_file(mock_csv_file):\n    \"\"\"Tests processing a file with only a header.\"\"\"\n    mock_opener = mock_csv_file(HEADER_ONLY_CSV_DATA)\n    with patch('builtins.open', mock_opener):\n         with pytest.raises(DataProcessingError, match=\"File contains only headers\"):\n            process_employee_data('dummy_path.csv')\n\n# Add more tests:\n# - Test division by zero if a department has count 0 for average calculation\n# - Test different data types in columns if applicable\n# - Test negative salaries if the validation logic changes\n</code></pre> <p>Setup &amp; Running Tests:</p> <ol> <li> <p>Save the refactored code as <code>data_processor_refactored.py</code>.</p> </li> <li> <p>Create a directory named <code>tests</code>.</p> </li> <li> <p>Save the test code as <code>test_data_processor.py</code> inside the <code>tests</code> directory.</p> </li> <li> <p>Make sure your virtual environment is active.</p> </li> <li> <p>Install necessary packages: <code>pip install pytest pytest-mock</code></p> </li> <li> <p>Navigate to the parent directory of your <code>tests</code> folder in the terminal.</p> </li> <li> <p>Run pytest: <code>pytest</code></p> </li> </ol> <p>This solution provides a solid refactoring incorporating many Chapter 1 concepts and includes basic unit tests to verify functionality and handle edge cases.</p>"}]}